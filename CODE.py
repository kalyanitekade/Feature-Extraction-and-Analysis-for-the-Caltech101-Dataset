# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1K17FlkJJT1bC9OrG5PfsmoY_ZrzpHCzD
"""

# Imports
import torch
import torchvision.models as models
import torchvision
from torchvision import datasets
import csv
import gzip
import pandas as pd
import numpy as np
from PIL import Image
import os
import glob
import warnings
warnings.filterwarnings('ignore')
from concurrent.futures import ThreadPoolExecutor
from scipy.stats import skew
from skimage.color import rgb2gray
from skimage.filters import sobel_h, sobel_v
from skimage import img_as_ubyte
from scipy.ndimage import histogram
import torchvision.transforms as transforms
import matplotlib
from scipy.spatial.distance import euclidean, cosine
from scipy.stats import pearsonr, entropy
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import wasserstein_distance as emd
from scipy.spatial import distance
from scipy.stats import pearsonr
from scipy.special import kl_div

resnet50 = models.resnet50(pretrained=True) # Load pre-trained ResNet-50 model
data_dir = './caltech101_data' # Define the data directory where you want to save the dataset
caltech_dataset = datasets.Caltech101(data_dir, download=True) # Download and extract the dataset

print(len(caltech_dataset))

for image_ID in range(8677):
    img, label = caltech_dataset[image_ID]
    print(image_ID)
    newsize = (60, 60)
    img = img.resize(newsize)
    display(img)

"""#RGB MODEL"""

all_feature_descriptors_rgb = {} #stores the RGB color moment for all the images of the dataset
def calculate_color_moments(channel_values):
    """Compute the color moments (mean, std dev, and skewness) for the given channel values."""
    num_pixels = channel_values.size

    # Mean calculation
    mean = np.sum(channel_values) / num_pixels

    # Standard Deviation calculation
    deviation_values = (channel_values - mean) ** 2
    stddev = np.sqrt(np.sum(deviation_values) / num_pixels)

    # Skewness calculation
    skewness_values = ((channel_values - mean) / stddev) ** 3 if stddev != 0 else 0
    skewness = np.cbrt(np.sum(skewness_values) / num_pixels)

    return np.array([mean, stddev, skewness])

def array_to_grid(nparray, divx, divy): #to divide the image into 10*10 grid
    grid = [np.array_split(row, divx, axis=1) for row in np.array_split(nparray, divy)]
    return np.array(grid)

def extract_features_rgb(image_array_grid):  #Extract the RGB color moments for image grid.
    rgb_feature_descriptor = [] #stores the CM for each of the grids in an image

    for row in image_array_grid:
        for cell in row:
            cellresult = [] #stores the CM for all the cells in the respective row
            for channel in range(cell.shape[2]): #cell.shape is 2 as we have rgb which is 3 channels
                channel_values = cell[:, :, channel]
                moments = calculate_color_moments(channel_values)
                cellresult.extend(moments)
            rgb_feature_descriptor.extend(cellresult)
    return np.array(rgb_feature_descriptor)  #return a numpy array of feature descriptors

def rgb_process_image(img):
    img = img.convert("RGB") #as few images are not in RGB to convert them
    image_array = np.array(img.resize((300, 100))) # Resize to the given specification
    image_array_grid = array_to_grid(image_array, 10, 10) # 10*10 is the size specified
    try:
        features = extract_features_rgb(image_array_grid)
        return features
    except Exception as e:
        print(f"ERROR (RGB): couldn't process image {image_ID}", e) #Executes only if the image is not able to process

for image_ID, (img, _) in enumerate(caltech_dataset): #goes through all the images in the dataset
    features = rgb_process_image(img) #sends the image to rgb_process_image
    all_feature_descriptors_rgb[image_ID] = features

processed_images_count_rgb = len(all_feature_descriptors_rgb)
print(processed_images_count_rgb) # print the number of images that are able to process

# Store features in CSV
def store_rgb_features_to_csv(all_feature_descriptors_rgb, csv_filename="rgb_features_data.csv"):
    with open(csv_filename, 'w', newline='') as csvfile:
        csv_writer = csv.writer(csvfile)
        header = ["image_id"] + [f"feature_{i}" for i in range(900)]
        csv_writer.writerow(header)
        for image_ID, feature_descriptor in all_feature_descriptors_rgb.items():
            row = [image_ID] + list(feature_descriptor)
            csv_writer.writerow(row)

store_rgb_features_to_csv(all_feature_descriptors_rgb)

"""#HOG"""

from scipy.ndimage import convolve

all_feature_descriptors_hog = {} #stores the HOG for all the images of the dataset

def array_to_grid(nparray,divx,divy):
    grid = [np.array_split(row, divx, axis=1) for row in np.array_split(nparray, divy)]
    return np.array(grid)

def compute_gradients(cell):  #Calculate the gradients using masks
    # Define the masks
    mask_x = np.array([[-1], [0], [1]])
    mask_y = mask_x.T  # Transposed

    # Calculate the gradients using convolution
    gradient_x = convolve(cell, mask_x, mode='reflect')
    gradient_y = convolve(cell, mask_y, mode='reflect')

    # Calculate the magnitude and orientation
    magnitude = np.sqrt(gradient_x**2 + gradient_y**2)
    orientation = (np.degrees(np.arctan2(gradient_y, gradient_x)) + 360) % 360  # Convert to degrees and map to [0, 360)

    return magnitude, orientation

def compute_histogram(magnitude, orientation, bins=9): #Calculate a histogram based on magnitude and orientation
    bin_width = 360 / bins
    hist, _ = np.histogram(orientation, bins=bins, range=(0, 360), weights=magnitude)
    return hist

def extract_hog_features(image_array_grid, bins=9): #Extracts HOG features for an image divided into a grid
    feature_descriptor_hog = []

    for row in image_array_grid:
        row_features = []
        for cell in row:
            cell =  img_as_ubyte(rgb2gray(cell)) #makes rgb image to grayscale
            magnitude, orientation = compute_gradients(cell)
            hist = compute_histogram(magnitude, orientation, bins)
            row_features.append(hist)
        feature_descriptor_hog.append(row_features)

    return np.array(feature_descriptor_hog)


def hog_process_image(img):
    img = img.convert("RGB") #makes all the images rgb
    image_array = np.array(img.resize((300, 100))) #resizes them
    image_array_grid = array_to_grid(image_array, 10, 10) #slices the image into grids
    try:
      features = extract_hog_features(image_array_grid)
      return features
    except Exception as e:
        print(f"ERROR (HOG): couldn't process image {image_ID}", e)

# Loop through the dataset to extract features for each image
for image_ID, (img, _) in enumerate(caltech_dataset):
    features = hog_process_image(img)
    all_feature_descriptors_hog[image_ID] = features
# Checks on the number of images processed correctly

processed_images_count_hog = len(all_feature_descriptors_hog)
print(processed_images_count_hog)

#Stores the feature in csv file

def store_hog_features_to_csv(all_feature_descriptors_hog, csv_filename="hog_features_data.csv"):
    with open(csv_filename, 'w', newline='') as csvfile:
        csv_writer = csv.writer(csvfile)
        header = ["image_id", "feature_type"] + [f"feature_{i}" for i in range(900)]
        csv_writer.writerow(header)
        for image_ID, feature_descriptor_hog in all_feature_descriptors_hog.items():
          row = [image_ID, "HOG"] + list(feature_descriptor_hog.flatten())
          csv_writer.writerow(row)

store_hog_features_to_csv(all_feature_descriptors_hog)

"""#AVG POOL

"""

# Checking if GPU is available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Loading the dataset
resnet = models.resnet50(pretrained=True).to(device)
resnet.eval()

all_feature_descriptors_avgpool={} #all the features extracted will be stored for all the image in the dataset

def avgpool_process_image(img):
    # Convert image to RGB if it is not in RGB
    if img.mode != 'RGB':
        img = img.convert('RGB')

    # Define the transformations
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) #normalising is done as a pretrained model is being used
    ])

    # Apply transformations to image
    tensor = transform(img).unsqueeze(0).to(device)

    return tensor

def hook_fn_avgpool(module, input, output): #hook is defined to extract features
    global features_avgpool
    features_avgpool = output

handle = resnet.avgpool.register_forward_hook(hook_fn_avgpool)

def get_features_avgpool(img):
    process_img = avgpool_process_image(img)
    with torch.no_grad(): #no gradient is required as no backpropogation is done
        _ = resnet(process_img)

    features_1024_avgpool = torch.mean(features_avgpool.view(features_avgpool.size(0), -1, 2), dim=-1) #makes 2048 features to 1024 by averaging

    return features_1024_avgpool


# Iterates over all the images in the dataset
for image_ID, (img, _) in enumerate(caltech_dataset):
        features = get_features_avgpool(img)
        all_feature_descriptors_avgpool[image_ID] = features.cpu().numpy()

# Checks for successfully processed images
processed_images_count_avgpool = len(all_feature_descriptors_avgpool)
print(processed_images_count_avgpool)

# Stores the feature in csv file
def store_avgpool_features_to_csv(all_feature_descriptors_avgpool, csv_filename="features_data_avgpool.csv"):
    with open(csv_filename, 'wt', newline='') as csvfile:
        csv_writer = csv.writer(csvfile)
        header = ["image_id", "feature_type"] + [f"feature_avgpool_{i}" for i in range(1024)]
        csv_writer.writerow(header)

        for image_id, feature_avgpool in all_feature_descriptors_avgpool.items():
          row = [image_id, "avg_pool"] + feature_avgpool[0].tolist()
          csv_writer.writerow(row)

store_avgpool_features_to_csv(all_feature_descriptors_avgpool)

# Removes the hook
handle.remove()

"""#LAYER THREE"""

# Checks if GPU is available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Device:", device)

# Loads ResNet model
resnet = models.resnet50(pretrained=True).to(device)
resnet.eval()

l3_features_from_hook = {}
l3_all_feature_descriptor = {}

def l3_hook_fn(module, input, output):
    global l3_features_from_hook
    l3_features_from_hook = output

handle = resnet.layer3.register_forward_hook(l3_hook_fn)

# Load and preprocess the image
def l3_process_image(img):
    # Convert image to RGB if it's not
    if img.mode != 'RGB':
        img = img.convert('RGB')

    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])
    return transform(img).unsqueeze(0).to(device)

def l3_get_features(img):
    processed_img = l3_process_image(img)
    with torch.no_grad():
        _ = resnet(processed_img)
    l3_features_1024 = l3_features_from_hook.mean([2, 3]).squeeze().cpu().numpy()
    return l3_features_1024

# Loop through the dataset to extract features for each image
for image_ID, (img, _) in enumerate(caltech_dataset):
        features = l3_get_features(img)
        l3_all_feature_descriptor[image_ID] = features

# Let's check how many images were processed successfully
processed_images_count_layer_three = len(l3_all_feature_descriptor)
print(processed_images_count_layer_three)

def store_l3_features_to_csv(l3_all_feature_descriptor, csv_filename="features_data_layer_three.csv"):
    with open(csv_filename, 'wt', newline='') as csvfile:
        csv_writer = csv.writer(csvfile)
        header = ["image_id", "feature_type"] + [f"feature_{i}" for i in range(1024)]
        csv_writer.writerow(header)
        for image_id, feature in l3_all_feature_descriptor.items():
          row = [image_id, "layer_3"] + list(feature)
          csv_writer.writerow(row)

store_l3_features_to_csv(l3_all_feature_descriptor)
# Remove the hook after use
handle.remove()

"""#FULLY CONNECTED"""

# Checks for GPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Device:", device)

# Loads ResNet model
resnet = models.resnet50(pretrained=True).to(device)
resnet.eval()

fc_features_from_hook = {}
fc_all_feature_descriptor = {}

# hook function:
def fc_hook_fn(module, input, output):
    global fc_features_from_hook
    fc_features_from_hook = output

handle = resnet.fc.register_forward_hook(fc_hook_fn)


# Load and preprocess the image
def fc_process_image(img):
    if img.mode != 'RGB':
        img = img.convert('RGB')
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])
    return transform(img).unsqueeze(0).to(device)

#feature vector
def fc_get_features(img):
    process_img = fc_process_image(img)
    with torch.no_grad():
        _ = resnet(process_img)
    return fc_features_from_hook.squeeze().cpu().numpy()

for image_ID, (img, _) in enumerate(caltech_dataset):
        features = fc_get_features(img)
        fc_all_feature_descriptor[image_ID] = features

processed_images_count_fclayer = len(fc_all_feature_descriptor)
print(processed_images_count_fclayer)


def store_fc_features_to_csv(fc_all_feature_descriptor, csv_filename="features_data_fc_layer.csv"):
    with open(csv_filename, 'wt', newline='') as csvfile:
        csv_writer = csv.writer(csvfile)
        header = ["image_id", "feature_type"] + [f"feature_{i}" for i in range(1000)]
        csv_writer.writerow(header)

        for image_id, feature in fc_all_feature_descriptor.items():
          row = [image_id, "fc_layer"] + list(feature)
          csv_writer.writerow(row)

store_fc_features_to_csv(fc_all_feature_descriptor)
# Remove the hook
handle.remove()

"""#FIND SIMILAR IMAGES"""

#Check if any cell has infinite or nan and replaces it  with meadian value of that column
def clean_csv_file(filename):
    """Clean the CSV file by replacing NaNs and infs with the median of the column."""
    df = pd.read_csv(filename)
    for column in df.columns:
        if df[column].dtype == 'float64':
            median_val = df[column].median()
            df[column] = df[column].replace([np.inf, -np.inf], median_val)
            df[column].fillna(median_val, inplace=True)
    df.to_csv(filename, index=False)

csv_files = ["rgb_features_data.csv", "hog_features_data.csv", "features_data_avgpool.csv",
             "features_data_layer_three.csv", "features_data_fc_layer.csv"]

for csv_file in csv_files:
    clean_csv_file(csv_file)


def load_features_from_csv(csv_filename): #Loads features from CSV file into a dictionary.
    features_dict = {}
    with open(csv_filename, 'r', newline='') as csvfile:
        csv_reader = csv.reader(csvfile)
        next(csv_reader, None)  # skips the header
        for row in csv_reader:
            image_id = int(float(row[0]))
            feature_vector = np.array([float(value) for value in row[2:]])
            features_dict[image_id] = feature_vector
    return features_dict

# Distance and similarity functions
def kl_divergence(p, q):
    p = p / np.sum(p)
    q = q / np.sum(q)
    epsilon = 1e-10
    p = p + epsilon
    q = q + epsilon
    return np.sum(kl_div(p, q))
def pearson_distance(u, v):
    if len(u) < 2 or len(v) < 2:
        return 1.0  # If vectors are too short, return maximum distance.
    corr, _ = pearsonr(u, v)
    return 1 - corr

# Get similar images
def get_most_similar_images(image_id, k, feature_data, distance_metric):
    distances = []
    target_features = feature_data[image_id]
    for img_id, features in feature_data.items():
        if img_id != image_id:
            # Check for same length when computing pearson_distance
            if distance_metric == pearson_distance and len(target_features) != len(features):
                continue
            dist = distance_metric(target_features, features) #computes the distance between the image id given and all other image in the datset
            distances.append((img_id, dist))
    sorted_distances = sorted(distances, key=lambda x: x[1])
    return sorted_distances[:k]

# Visualization function

def visualize_similar_images(image_id, k, feature_data_dict, caltech_dataset): #Visualize the most similar images to the given image ID based on different feature data
    if image_id >= len(caltech_dataset): #checks if the user image id is not greater than the len of dataset
        print(f"Image ID {image_id} is out of range for the dataset.")
        return
    plt.figure(figsize=(5, 5))
    ref_img, _ = caltech_dataset[image_id]
    plt.imshow(ref_img)
    plt.title(f"Reference Image ID: {image_id}")
    plt.axis('off')
    plt.show()
    for feature_type, feature_data in feature_data_dict.items():
        if image_id not in feature_data:
            print(f"Features not available for Image ID {image_id} in {feature_type} data.")
            continue
        plt.figure(figsize=(50, 50))
        similar_images = get_most_similar_images(image_id, k, feature_data, distance_metric=distance_metrics[feature_type])
        for idx, (img_id, distance) in enumerate(similar_images, 1):
            if img_id >= len(caltech_dataset):
                continue
            img, _ = caltech_dataset[img_id]
            plt.subplot(1, k, idx)
            plt.imshow(img)
            plt.title(f"Image ID: {img_id}\n{feature_type} Distance: {distance:.2f}", fontsize=18)
            plt.axis('off')
        plt.subplots_adjust(wspace=9.0)
        plt.tight_layout()
        plt.show()


# Give input
image_id_input = int(input("Enter the image ID: "))
k_input = int(input("Enter the value of k (number of similar images to retrieve): "))

rgb_features = load_features_from_csv("rgb_features_data.csv")
hog_features = load_features_from_csv("hog_features_data.csv")
avgpool_features = load_features_from_csv("features_data_avgpool.csv")
l3_features = load_features_from_csv("features_data_layer_three.csv")
fc_features = load_features_from_csv("features_data_fc_layer.csv")

feature_data_dict = {
    'rgb': rgb_features,
    'hog': hog_features,
    'avgpool': avgpool_features,
    'l3': l3_features,
    'fc': fc_features,
}

distance_metrics = {
    'rgb': distance.euclidean,
    'hog': kl_divergence,
    'avgpool': pearson_distance,
    'l3': pearson_distance,
    'fc': pearson_distance
}
visualize_similar_images(image_id_input, k_input, feature_data_dict, caltech_dataset)